rm(list=ls())

# Let's investigate the slope estimator (b1)
# Start by reading the csv into a df
trees <- read.csv("../Datasets/Tree_Equity_Scores_Tucson_noNA.csv")
# create a fitted object and look at the summary of the fit
fit_trees <- lm(HeatSeverity ~ PCTTreeCover, data = trees)
summary(fit_trees)

# To create the confidence interval of slope estimator b1, we need values for
# constructing the standard deviation of b1: sb1 = rse/sqrt(sum((xi-x_bar)^2))

# residual standard error RSE = sqrt(MSE)
rse <- 1.203
# the slope estimator b1
coef(fit_trees)
b1 <- -0.173
# standard deviation of the slope estimator b1: use formula
xi <- trees$PCTTreeCover
x_bar <- mean(trees$PCTTreeCover)
sb1 <- rse/sqrt(sum((xi-x_bar)^2))

# b1 is t-distributed since it estimates variance with s
# Let's compute a 94% confidence interval with the value of sb1 and
# plug into the formula : b1 +/- t*sb1

# p degrees of freedom
p <- 403
# plug in formula
b1 + qt(c(0.03,0.97), p) * sb1

# Now compare with R function confint() for b1's 94% confidence interval
confint(object = fit_trees, level = 0.94)[2,]  

# Conclusion: basically the same except for rounding errors
##################################################################################
# Now let's investigate the estimator for a single prediction Yj_hat which 
# approximates the actual expected Yi E[Yi] for xj-th observation
# Note: xj is not a new observation, it is already included in the data used for 
# inference.

# We again want to compute the CI of our single prediction estimator: Yj_hat
# This is again t-distributed since it estimates variance from the sample.
# The formula for this is: sYhat^2 <- mse*( (1/n) + (xj-x_bar)^2 / sum(xi-x_bar)^2 )
# and for sYhat is just the square root: rse * sqrt( the same stuff )

# n is number of observations xi
n = length(trees$PCTTreeCover)
# let's look at the Yj_hat prediction associated with the xj observation
xj = 15

# we have rse, x_bar, and xi from constructing the b1 confidence interval
# so now we comput sYhat:
sYhat <- rse * sqrt( (1/n) + (xj-x_bar)^2 / sum((xi-x_bar)^2) )

# Now we can use the sYhat we have computed to create a 95% confidence interval
# using the t-distribution

# First compute Yj_hat using the coefficients from the linear fit
coef(fit_trees)
b0 <- coef(fit_trees)[[1]]
b1 <- coef(fit_trees)[[2]]
Yj_hat <- b0 + b1*xj

# Now we can add the t distr. quantiles scaled by the standard deviation sYhat
# to both sides of our estimator Yj_hat to create our confidence interval.
Yj_hat + qt(c(0.025, 0.975), p) * sYhat

# And we can compare to the confidence interval generated by the predict() function 
# in R for the predicted value corresponding to xj
predict(object = fit_trees, newdata = data.frame(PCTTreeCover = xj),
        interval = 'confidence')

# Conclusion: again, we see that the mechanically-computed, and R function generated 
# values are nearly identical (with room for rounding differences)

###########################################################################################
# Now let's look at the estimator for a new observation Ynew_hat

# Again, start with the standard deviation. Recall for a new observation,
# sYnew_hat^2 = sigma^2 + sYhat^2 = MSE + sYhat^2 since MSE estimates sigma^2
# Then sYnew_hat = sqrt(sYnew_hat^2)
sYnew_hat_squared = rse^2 + sYhat^2
sYnew_hat = sqrt(sYnew_hat_squared)

# Now with sYnew_hat, we can calculate the confidence interval with a t distribution
xnew <- 15
Ynew_hat <- b0 + b1*xnew

Ynew_hat + qt(c(0.025,0.975), 403) * sYnew_hat

# And repeating with the R function predict() with the new argument interval = 'predict'
predict(object = fit_trees, newdata = data.frame(PCTTreeCover = xnew),
        interval = 'predict')

# Conclusion: again, pretty identical

##########################################################################################

# We can also create confidence bands for the regression curve as a whole
## Working-Hotelling Band function
pred_WH <- function(object, newdata, level = 0.95){
  fit <- predict(object, newdata) ## Yhat
  MSE <- summary(object)$sigma^2
  n <- nrow(object$model) ## extract n from model object
  W <- sqrt(2 * qf(level, 2, n - 2))
  
  # use the attr() function: The first argument takes the object with 
  # attributes you want to access. The other argument is a string of the attribute
  # you would like to access.
  
  # You will use this to get the term labels from the list of terms used in the object (object$terms)
  # With the term labels, you can access by indexing the corresponding data input into the model:
  # x_obs <- object$model[,c(term_labels)]
  X_obs <- object$model[, attr(object$terms, "term.labels")]
  X <- newdata[, attr(object$terms, "term.labels")]
  ME <- W * sqrt(MSE * (1 / n + (X - mean(X_obs))^2 / 
                          sum((X_obs - mean(X_obs))^2)))
  upr <- fit + ME
  lwr <- fit - ME
  return(cbind(fit, lwr, upr))
}

# The rest of the simulation is in the supplemental document here:
source("./Session 4 supp confidence_bands.R")

# Essentially you run a simulation and use a pointwise method 
# to create confidence band around the regression line.
# Then you create another function using the Working-Hotelling method
# and create another confidence band. The results show that the pointwise
# method fails to adequately cover 95% of the observed and is therefore
# not a good method for creating confidence bands for a regression line